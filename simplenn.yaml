name: SimpleNN creation in pytorch
description: Fetches nested JSON from API and extracts all content and titles for model training
inputs:
  - {name: api_url, type: String, description: 'API URL to fetch structured document JSON'}
  - {name: access_token, type: String, description: 'Bearer access token for API auth'}
outputs:
  - {name: extracted_text, type: Data}
  - {name: metadata, type: Data}
implementation:
  container:
    image: nikhilv215/nesy-factory:v22
    command:
      - sh
      - -c
      - |
        exec "$0" "$@"
      - python3
      - -u
      - -c
      - |
        import argparse
        import os
        import json
        import pandas as pd
        import requests
        from requests.adapters import HTTPAdapter
        from urllib3.util.retry import Retry
        import logging
        from typing import List, Dict, Any

        import torch
        import torch.nn as nn
        import torch.nn.functional as F
        import torch.optim as optim
        from sklearn.metrics import accuracy_score
        import numpy as np
        import matplotlib.pyplot as plt
        from sklearn.datasets import make_classification
        from sklearn.model_selection import train_test_split
        from sklearn.preprocessing import StandardScaler


        parser = argparse.ArgumentParser()
        parser.add_argument('--api_url', type=str, required=True)
        parser.add_argument('--access_token', type=str, required=True)
        parser.add_argument('--extracted_text', type=str, required=True)
        parser.add_argument('--metadata', type=str, required=True)
        args = parser.parse_args()

        logging.basicConfig(level=logging.INFO)
        logger = logging.getLogger('text_extractor')

        X,y = make_classification(n_samples=500, n_features=2, n_informative=2, n_redundant=0, n_clusters_per_class=1, random_state=42)


        scalar = StandardScaler()
        X_Scaled = scalar.fit_transform(X)


        X_train, X_test, y_train, y_test = train_test_split(X_Scaled, y, test_size=0.2, random_state=42)

        X_train_tensor = torch.tensor(X_train, dtype=torch.float32)
        y_train_tensor = torch.tensor(y_train.reshape(-1,1), dtype=torch.float32)
        X_test_tensor = torch.tensor(X_test, dtype=torch.float32)
        y_test_tensor = torch.tensor(y_test.reshape(-1,1), dtype =torch.float32)



        class SimpleNN(nn.Module):
            def __init__(self, input_dim):
                super(SimpleNN, self).__init__()
                self.fc1 = nn.Linear(input_dim, 10)
                self.fc2 = nn.Linear(10,1)

            def forward(self, x):
                x = F.relu(self.fc1(x))
                x = torch.sigmoid(self.fc2(x)) # Pass the output of fc1 to fc2
                return x

        model = SimpleNN(input_dim=2)
        criterion = nn.BCELoss()
        optimizer = optim.Adam(model.parameters(), lr = 0.01)


        num_epochs = 100
        train_accuracies = []
        test_accuracies = []
        losses = [] # Changed variable name from 'loss' to 'losses'

        for epoch in range(num_epochs):
            # Forward pass
            model.train()
            outputs = model(X_train_tensor)
            loss = criterion(outputs, y_train_tensor)

            # Backward and optimize
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

            # Calculate and store accuracies
            model.eval()
            with torch.no_grad():
                train_outputs = model(X_train_tensor)
                train_predictions = (train_outputs > 0.5).float()
                train_accuracy = accuracy_score(y_train_tensor, train_predictions)
                train_accuracies.append(train_accuracy)

                test_outputs = model(X_test_tensor)
                test_predictions = (test_outputs > 0.5).float()
                test_accuracy = accuracy_score(y_test_tensor, test_predictions)
                test_accuracies.append(test_accuracy)

            losses.append(loss.item()) # Store the loss value

            if (epoch+1) % 10 == 0:
                print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}, Train Accuracy: {train_accuracy:.4f}, Test Accuracy: {test_accuracy:.4f}')

        model.eval()
        with torch.no_grad():
            train_outputs = model(X_train_tensor)
            train_predictions = (train_outputs > 0.5).float()
            train_accuracy = accuracy_score(y_train_tensor, train_predictions)
            print(f'Training Accuracy: {train_accuracy:.4f}')

        # Save outputs
        os.makedirs(os.path.dirname(args.extracted_text), exist_ok=True)
        os.makedirs(os.path.dirname(args.metadata), exist_ok=True)

        # Save training results
        results = {
            'final_train_accuracy': float(train_accuracy),
            'train_accuracies': train_accuracies,
            'test_accuracies': test_accuracies,
            'losses': losses
        }

        with open(args.extracted_text, 'w') as f:
            json.dump(results, f)

        # Save model metadata
        metadata = {
            'model_type': 'SimpleNN',
            'input_dim': 2,
            'num_epochs': num_epochs,
            'learning_rate': 0.01,
            'dataset_size': len(X_train)
        }

        with open(args.metadata, 'w') as f:
            json.dump(metadata, f)

        print("Training completed and results saved.")


    args:
      - --api_url
      - {inputValue: api_url}
      - --access_token
      - {inputValue: access_token}
      - --extracted_text
      - {outputPath: extracted_text}
      - --metadata
      - {outputPath: metadata}
