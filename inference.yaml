name: Inference and Anomaly Detection
description: Runs inference on a query data point and detects anomalies using the trained model and dataset.

inputs:
  - name: query
    type: string
    description: "Query input for inference"
  - name: dataset
    type: Dataset
    description: "Full dataset including test/validation splits"
  - name: model_weights
    type: Model
    description: "Trained model weights for inference"
  - name: config
    type: string
    description: "Optional config JSON string for model"

outputs:
  - name: inference_result
    type: string
    description: "JSON result of inference and anomaly detection"

implementation:
  container:
    image: gurpreetgandhi/nesy-factory:v12
    command:
      - sh
      - -c
      - |
        python3 -m pip install || \
        python3 -m pip install --user
        exec "$0" "$@"
      - python3
      - -u
      - -c
      - |
        import argparse, os, pickle, torch, json
        
        parser = argparse.ArgumentParser()
        parser.add_argument('--query', type=str, required=True, help='Query input for inference')
        parser.add_argument('--dataset', type=str, required=True, help='Path to dataset pickle file')
        parser.add_argument('--model_weights', type=str, required=True, help='Path to trained model weights')
        parser.add_argument('--config', type=str, required=False, help='Optional config JSON string')
        parser.add_argument('--inference_result', type=str, required=True, help='Path to save inference result JSON')
        args = parser.parse_args()
        
        # Load dataset
        with open(args.dataset, "rb") as f:
            data = pickle.load(f)
        
        # Load config
        config = json.loads(args.config) if args.config else {}
        
        # Load model class dynamically (placeholder)
        from nesy_factory.GNNs import STGNNModel  # adjust if needed
        model = STGNNModel(config)
        model.load_state_dict(torch.load(args.model_weights, map_location="cpu"))
        
        # Define inference function
        def infer_and_detect_anomaly(model, data, config):
            inference_idx = 100
            if len(data.x_test) <= inference_idx:
                print(f"Test set has less than {inference_idx + 1} data points.")
                return {}
            
            single_x = torch.Tensor(data.x_test[inference_idx:inference_idx+1]).to(model.device)
            single_y_true = data.y_test[inference_idx:inference_idx+1]
            
            json_result = model.infer_step(
                single_x=single_x,
                single_y_true=single_y_true,
                val_loader=data.val_loader,
                y_val=data.y_val,
                scaler=data.scaler,
                num_components=8
            )
            return json_result
        
        result = infer_and_detect_anomaly(model, data, config)
        
        os.makedirs(os.path.dirname(args.inference_result) or ".", exist_ok=True)
        with open(args.inference_result, "w") as f:
            json.dump(result, f, indent=2)
        
        print(" Inference completed. Results saved.")

    args:
      - --query
      - inputValue: query
      - --dataset
      - inputPath: dataset
      - --model_weights
      - inputPath: model_weights
      - --config
      - inputValue: config
      - --inference_result
      - outputPath: inference_result
