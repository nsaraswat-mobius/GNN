name: V_Train_GNN_FF_Fixed
description: Trains GNN with BULLETPROOF STGNN support (torchvision fully blocked)
inputs:
  - {name: data_path, type: Dataset}
  - {name: model, type: Model}
  - {name: config, type: String}
outputs:
  - {name: trained_model, type: Model}
  - {name: epoch_loss, type: String}

implementation:
  container:
    image: gurpreetgandhi/nesy-factory:v38-gpu
    command:
      - sh
      - -c
      - |
        exec "$0" "$@"
      - python3
      - -u
      - -c
      - |
        import os
        import sys
        import json
        import pickle
        import argparse
        import numpy as np

        # ---------------------------------------------------------
        #  HARD BLOCK TORCHVISION (NO EXTENSIONS, NO CIRCULAR IMPORT)
        # ---------------------------------------------------------
        if "torchvision" in sys.modules:
            del sys.modules["torchvision"]

        original_import = __builtins__.__import__

        def block_torchvision_import(name, *args, **kwargs):
            if name.startswith("torchvision"):
                import types
                dummy = types.ModuleType(name)
                sys.modules[name] = dummy
                print(f"BLOCKED torchvision import: {name}")
                return dummy
            return original_import(name, *args, **kwargs)

        __builtins__.__import__ = block_torchvision_import

        import torch
        import torch.nn as nn
        import torch.optim as optim

        print("PyTorch imported successfully with torchvision BLOCKED")

        from nesy_factory.GNNs.stgnn import STGNN

        __builtins__.__import__ = original_import
        print("Import system restored")

        # ---------------------------------------------------------
        # ARGUMENTS
        # ---------------------------------------------------------
        parser = argparse.ArgumentParser()
        parser.add_argument("--data_path", required=True)
        parser.add_argument("--model", required=True)
        parser.add_argument("--config", required=True)
        parser.add_argument("--trained_model", required=True)
        parser.add_argument("--epoch_loss", required=True)
        args = parser.parse_args()

        os.makedirs(os.path.dirname(args.trained_model), exist_ok=True)
        os.makedirs(os.path.dirname(args.epoch_loss), exist_ok=True)

        # ---------------------------------------------------------
        # LOAD DATA
        # ---------------------------------------------------------
        with open(args.data_path, "rb") as f:
            data = pickle.load(f)

        X = data.x
        y = data.y

        #  FIX DATA SHAPE: [B,T,N,C] â†’ [B,C,N,T]
        X = X.permute(0, 3, 2, 1).contiguous()
        y = y.permute(0, 3, 2, 1).contiguous()

        # ---------------------------------------------------------
        # LOAD CONFIG
        # ---------------------------------------------------------
        config = json.loads(args.config)

        #  REMOVE POISON KEYS
        config.pop("input_dim", None)
        config.pop("output_dim", None)

        # ---------------------------------------------------------
        # TRAINING MODE (BOOLEAN CONTROLLED)
        # ---------------------------------------------------------
        training_mode = (
            "forward_forward"
            if config.get("use_forward_forward", False)
            else "cafo"
            if config.get("use_cafo", False)
            else "traditional"
        )

        print("Training mode:", training_mode)

        # ---------------------------------------------------------
        # CREATE MODEL
        # ---------------------------------------------------------
        model = STGNN(config)

        # ---------------------------------------------------------
        # TRAIN
        # ---------------------------------------------------------
        losses = []

        if training_mode == "cafo":
            result = model.train_cafo((X, y))
            losses = result["block_results"]

        elif training_mode == "forward_forward":
            result = model.train_forward_forward((X, y))
            losses = result["block_results"]

        else:
            optimizer = optim.Adam(model.parameters(), lr=config["learning_rate"])
            criterion = nn.MSELoss()

            for epoch in range(config["epochs"]):
                optimizer.zero_grad()
                out = model(X)
                loss = criterion(out, y)
                loss.backward()
                optimizer.step()
                losses.append(float(loss.item()))

        # ---------------------------------------------------------
        # SAVE OUTPUTS (ARGO SAFE)
        # ---------------------------------------------------------
        torch.save(model.state_dict(), args.trained_model)

        with open(args.epoch_loss, "w") as f:
            json.dump(
                {
                    "training_mode": training_mode,
                    "losses": losses,
                },
                f,
                indent=2,
            )

        print(" TRAINING COMPLETED SUCCESSFULLY")
    args:
      - --data_path
      - {inputPath: data_path}
      - --model
      - {inputPath: model}
      - --config
      - {inputValue: config}
      - --trained_model
      - {outputPath: trained_model}
      - --epoch_loss
      - {outputPath: epoch_loss}
