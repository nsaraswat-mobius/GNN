name: V_Train_GNN_FF_Fixed
description: Trains GNN with STGNN support (NEGATIVE TENSOR FIXED)
inputs:
  - {name: data_path, type: Dataset}
  - {name: model, type: Model}
  - {name: config, type: String}
outputs:
  - {name: trained_model, type: Model}
  - {name: epoch_loss, type: String}

implementation:
  container:
    image: gurpreetgandhi/nesy-factory:v38-gpu
    command:
      - sh
      - -c
      - |
        exec "$0" "$@"
      - python3
      - -u
      - -c
      - |
        import os, sys, json, pickle, argparse
        import torch
        import numpy as np

        sys.path.insert(0, "/app/src")
        sys.path.insert(0, "/workspace/src")
        sys.path.insert(0, "/code/src")

        from nesy_factory.GNNs.stgnn import STGNN

        parser = argparse.ArgumentParser()
        parser.add_argument("--data_path", type=str, required=True)
        parser.add_argument("--model", type=str, required=True)
        parser.add_argument("--config", type=str, required=True)
        parser.add_argument("--trained_model", type=str, required=True)
        parser.add_argument("--epoch_loss", type=str, required=True)
        args = parser.parse_args()

        # ---------------- CONFIG ----------------
        config = json.loads(args.config)

        #  MUST REMOVE (CAUSES NEGATIVE DIM)
        config.pop("input_dim", None)
        config.pop("output_dim", None)

        #  BULLETPROOF STGNN LIMITS
        config["seq_in_len"] = max(12, int(config["seq_in_len"]))
        config["layers"] = max(1, int(config["layers"]))
        config["kernel_size"] = min(
            int(config.get("kernel_size", 3)),
            config["seq_in_len"] - 1
        )

        # ---------------- DATA ----------------
        with open(args.data_path, "rb") as f:
            data = pickle.load(f)

        X = torch.tensor(data.x, dtype=torch.float32)
        Y = torch.tensor(data.y, dtype=torch.float32)

        #  CRITICAL FIX
        # BEFORE: [B, T, N, C]
        # AFTER : [B, C, N, T]
        X = X.permute(0, 3, 2, 1).contiguous()
        Y = Y.permute(0, 3, 2, 1).contiguous()

        # HARD ASSERTS (FAIL FAST)
        assert X.shape[1] == config["in_dim"]
        assert X.shape[2] == config["num_nodes"]
        assert X.shape[3] == config["seq_in_len"]

        # ---------------- MODEL ----------------
        model = STGNN(config)

        #  FIX NameError
        training_mode = (
            "forward_forward"
            if config.get("use_forward_forward", False)
            else "cafo"
            if config.get("use_cafo", False)
            else "traditional"
        )

        loss_history = []

        # ---------------- TRAIN ----------------
        if config.get("use_cafo", False) and hasattr(model, "train_cafo"):
            result = model.train_cafo((X, Y), verbose=True)
            for b, block in enumerate(result["block_results"]):
                for e, loss in enumerate(block["train_losses"]):
                    loss_history.append({
                        "block": b + 1,
                        "epoch": e + 1,
                        "loss": float(loss),
                        "mode": "cafo"
                    })

        elif config.get("use_forward_forward", False) and hasattr(model, "train_forward_forward"):
            result = model.train_forward_forward((X, Y), verbose=True)
            for b, block in enumerate(result["block_results"]):
                for e, loss in enumerate(block["train_losses"]):
                    loss_history.append({
                        "block": b + 1,
                        "epoch": e + 1,
                        "loss": float(loss),
                        "mode": "forward_forward"
                    })

        # ---------------- SAVE ----------------
        os.makedirs(os.path.dirname(args.trained_model), exist_ok=True)
        os.makedirs(os.path.dirname(args.epoch_loss), exist_ok=True)

        torch.save(model.state_dict(), args.trained_model)

        with open(args.epoch_loss, "w") as f:
            json.dump({
                "training_mode": training_mode,
                "loss_history": loss_history
            }, f, indent=2)

        print(" STGNN TRAINING COMPLETED SUCCESSFULLY")

    args:
      - --data_path
      - {inputPath: data_path}
      - --model
      - {inputPath: model}
      - --config
      - {inputValue: config}
      - --trained_model
      - {outputPath: trained_model}
      - --epoch_loss
      - {outputPath: epoch_loss}
