name: Load Weights from CDN
description: Downloads model weights from a CDN URL with retry logic and makes them available for inference.

inputs:
  - name: weights_cdn_url
    type: string
    description: "CDN URL to download model weights (.pth/.pt/.pkl)"
  - name: access_token
    type: string
    description: "Optional Bearer access token file for CDN auth"
  - name: pickle_cdn_url
    type: string
    description: "CDN URL to download supplementary pickle file"

outputs:
  - name: model_weights
    type: Model
    description: "Downloaded model weights for inference"
  - name: pickle_file
    type: Dataset
    description: "Downloaded pickle file"

implementation:
  container:
    image: gurpreetgandhi/nesy-factory:v12
    command:
      - python3
      - -u
      - -c
      - |
        import argparse, os, requests, logging
        from requests.adapters import HTTPAdapter
        from urllib3.util.retry import Retry

        parser = argparse.ArgumentParser()
        parser.add_argument('--weights_cdn_url', type=str, required=True, help='CDN URL of weights file')
        parser.add_argument('--access_token', type=str, required=False, help='Path to access token file')
        parser.add_argument('--pickle_cdn_url', type=str, required=False, help='CDN URL of pickle file')
        parser.add_argument('--model_weights', type=str, required=True, help='Path to save model weights')
        parser.add_argument('--pickle_file', type=str, required=True, help='Path to save pickle file')
        args = parser.parse_args()

        # Load token if provided
        headers = {}
        if args.access_token and os.path.exists(args.access_token):
            with open(args.access_token, 'r') as f:
                token = f.read().strip()
                headers["Authorization"] = f"Bearer {token}"

        # Setup retry logger
        logging.basicConfig(level=logging.INFO)
        logger = logging.getLogger("cdn_retry")

        # Setup session with retries
        session = requests.Session()
        retries = Retry(
            total=5,
            backoff_factor=1,
            status_forcelist=[500, 502, 503, 504],
            allowed_methods=["GET"]
        )
        adapter = HTTPAdapter(max_retries=retries)
        session.mount("http://", adapter)
        session.mount("https://", adapter)

        def download_file(url, out_path, name):
            logger.info(f" Downloading {name} with retry + timeout")
            resp = session.get(url, headers=headers, stream=True, timeout=60)
            resp.raise_for_status()
            os.makedirs(os.path.dirname(out_path) or ".", exist_ok=True)
            with open(out_path, "wb") as f:
                for chunk in resp.iter_content(chunk_size=8192):
                    if chunk:
                        f.write(chunk)
            logger.info(f" {name} successfully downloaded to {out_path}")

        try:
            download_file(args.weights_cdn_url, args.model_weights, "weights")
            if args.pickle_cdn_url:
                download_file(args.pickle_cdn_url, args.pickle_file, "pickle file")
        except requests.exceptions.RequestException as e:
            logger.error(f" Failed to download file after retries: {e}")
            raise

    args:
      - --weights_cdn_url
      - inputValue: weights_cdn_url
      - --access_token
      - inputPath: access_token
      - --pickle_cdn_url
      - inputValue: pickle_cdn_url
      - --model_weights
      - outputPath: model_weights
      - --pickle_file
      - outputPath: pickle_file
